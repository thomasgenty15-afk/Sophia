### Fiche commandes — tests & jobs internes (local)

Prérequis:
- Docker (Supabase local)
- Node + npm
- Deno (pour les tests Deno dans `supabase/functions/**/*_test.ts`, inclut les tests “tools agents”)
- (Optionnel E2E) Playwright browsers (voir plus bas)

---

### Test ultime (A→Z) — 1 commande

#### SMOKE (rapide, fiable, sans dépendre de Gemini)
Start Supabase + reset DB + tests Deno + tests Vitest d’intégration (inclut flows “UI” DB + triggers DB non-edge).

```bash
npm run test:mega
```

#### FULL (inclut triggers/cron → Edge Functions → effets DB comme `memories`, `user_core_identity`, archive)
```bash
npm run test:mega -- --full
```

#### FULL + IA réelle (Gemini + embeddings)
⚠️ plus lent + dépend du réseau/quotas/coût. Nécessite `GEMINI_API_KEY` configurée dans les secrets Edge.

```bash
npm run test:mega -- --full --ai
```

#### Options utiles
```bash
# ne reset pas la DB
npm run test:mega -- --no-reset

# isoler une partie
npm run test:mega -- --skip-deno
npm run test:mega -- --skip-frontend

# inclure les tests E2E UI (Playwright)
npm run test:mega -- --full --no-reset --e2e
```

---

### Lancer une partie seulement

#### Vitest (tests d’intégration frontend)
```bash
cd frontend
npm run test:int
```

#### Vitest (sécurité / RLS) — tests “négatifs” (doivent échouer côté DB)
Inclus dans `npm run test:int` et donc dans `test:mega`, mais tu peux les cibler :

```bash
cd frontend
npx vitest run src/security/rls-negative.int.test.ts
```

#### Deno (tests unitaires des helpers Edge)
```bash
cd supabase/functions
deno test -A --no-lock
```

#### Playwright (tests E2E UI: clics réels)

1) Installer les browsers (une fois) :

```bash
cd frontend
npm run test:e2e:install
```

2) Lancer les E2E :

```bash
cd frontend
npm run test:e2e
```

#### Playwright (stress / volume) — Chat
Ce test est inclus dans `npm run test:e2e` :

```bash
cd frontend
npx playwright test e2e/stress-chat.e2e.spec.ts
```

Astuce (recommandé) : lancer via le mega-test pour avoir les variables d’env automatiquement :

```bash
npm run test:mega -- --full --no-reset --e2e
```

#### Supabase local
```bash
npm run db:start
npm run db:reset
npm run db:stop
```

---

### Jobs internes (cron) — reset / sync / trigger manuel

#### Après un `db reset`, est-ce qu’il faut refaire les crons ?
Oui. Un reset remet la DB à zéro → les jobs `pg_cron` disparaissent.

#### Reset “safe” (ne pousse aucun secret)
```bash
./scripts/local_reset.sh
```

#### (Optionnel) Si tu utilises des jobs internes en local
Si tu as des 403 sur des Edge Functions “internes” (jobs/cron), synchronise le secret **uniquement en local** (Vault) :

```bash
./scripts/local_sync_internal_secret.sh
```

Puis tu peux déclencher un job manuellement :

```bash
./scripts/local_trigger_internal_job.sh detect-future-events
./scripts/local_trigger_internal_job.sh process-checkins
./scripts/local_trigger_internal_job.sh trigger-memory-echo
```

---

### (Legacy) Déclencher une fonction interne via curl + secret récupéré depuis Vault



















0) Récupérer le secret (sans l’afficher) + helper

```bash
SECRET="$(docker exec -i supabase_db_Sophia_2 psql -U postgres -d postgres -tA -c \
"select decrypted_secret from vault.decrypted_secrets where name='INTERNAL_FUNCTION_SECRET' limit 1;")"
```

1) Déclencher `detect-future-events`

```bash
curl -s -X POST "http://127.0.0.1:54321/functions/v1/detect-future-events" \
  -H "Content-Type: application/json" \
  -H "X-Internal-Secret: $SECRET" \
  -d '{}' | cat
```

2) Déclencher `process-checkins`

```bash
curl -s -X POST "http://127.0.0.1:54321/functions/v1/process-checkins" \
  -H "Content-Type: application/json" \
  -H "X-Internal-Secret: $SECRET" \
  -d '{}' | cat
```

3) (optionnel) Déclencher `trigger-memory-echo`

```bash
curl -s -X POST "http://127.0.0.1:54321/functions/v1/trigger-memory-echo" \
  -H "Content-Type: application/json" \
  -H "X-Internal-Secret: $SECRET" \
  -d '{}' | cat


4) Déclencher "Trigger daily bilan"
curl -s -X POST "http://127.0.0.1:54321/functions/v1/trigger-daily-bilan" \
  -H "Content-Type: application/json" \
  -H "X-Internal-Secret: $SECRET" \
  -d '{}' | cat
```

<<<<<<< HEAD
=======

>>>>>>> staging
SUPABASE POUR SELECT le bon projet : 
Avec la CLI (pour éviter une boulette)
1) Liste les projets :
list
supabase projects list
2) Link explicitement :
iabxchanerdkczbxyjgg
supabase link --project-ref iabxchanerdkczbxyjgg
3) Vérifie le ref enregistré localement :
ref
cat supabase/.temp/project-ref
Si ce fichier affiche iabxchanerdkczbxyjgg, tu es sur le bon projet.



GIT pour selectionner le bon projet : 
git status
git branch

<<<<<<< HEAD
Pour se mettre sur le bon projet : 
git checkout main (ou staging ) ou git switch main
git switch staging
git checkout main
git merge staging
git push origin main

=======
>>>>>>> staging
Pour pousser (vers staging): 
    git add .
    git commit -m " "
    git push origin staging




SUPPRIMER TOUS LES SECRETS DE LA BD : 
for k in $(supabase secrets list | awk 'NR>1 && $1!="NAME"{print $1}'); do
  supabase secrets unset "$k"
done


Script “supprimer partout où user_id = ce user” (cloud Supabase)
À coller dans Supabase Dashboard → SQL Editor (⚠️ irréversible) :
1) Récupère l’UUID :
select id, email
from auth.users
where email = 'EMAIL_DE_L_USER';

2) Purge toutes les lignes qui ont une colonne user_id + suppression du user :


do $$
declare
  uid uuid := 'UUID';
  r record;
begin
  -- 1) supprimer l'utilisateur auth (déclenche les cascades)
  delete from auth.users where id = uid;

  -- 2) nettoyer toutes les tables public qui ont une colonne uid (user_id / profile_id / id)
  for r in
    select table_schema, table_name, column_name
    from information_schema.columns
    where table_schema = 'public'
      and udt_name = 'uuid'
      and column_name in ('user_id', 'profile_id', 'id')
  loop
    execute format('delete from %I.%I where %I = %L', r.table_schema, r.table_name, r.column_name, uid);
  end loop;
end
$$;


  -- 2) profiles: la colonne s'appelle id (pas user_id)
  delete from public.profiles where id = uid;

  -- 3) supprime le user auth (nettoie le reste via FK / cascade / set null côté auth)
  delete from auth.users where id = uid;
end $$;

commit;




Pour lancer supabase avec le .env : 
npx supabase functions serve --env-file supabase/.env



Trigger le bilan : 
./scripts/local_trigger_internal_job.sh trigger-daily-bilan




COMMMANDE POUR TOUT OUVRIR POUR UN UTILISATEUR : 


begin;

with
  params as (
    select '__USER_ID__'::uuid as uid
  ),

  -- 1) Semaines + portes d’entrée Forge/Table Ronde
  weeks as (
    select generate_series(1, 12) as w
  ),
  week_state_ids as (
    select format('week_%s', w) as module_id from weeks
    union all select 'forge_access'
    union all select 'round_table_1'   -- uniquement celle-ci
  ),
  upsert_week_states as (
    insert into public.user_week_states (user_id, module_id, status, available_at, completed_at)
    select p.uid, ids.module_id, 'available', now(), null
    from params p
    cross join week_state_ids ids
    on conflict (user_id, module_id) do update
      set
        status = case when public.user_week_states.status = 'completed' then 'completed' else 'available' end,
        available_at = least(public.user_week_states.available_at, excluded.available_at),
        completed_at = case when public.user_week_states.status = 'completed' then public.user_week_states.completed_at else null end,
        updated_at = now()
    returning 1
  ),

  -- 2) Forge: débloquer tous les modules aX_cY_m{2..5} (toutes semaines, toutes cartes)
  cards as (
    select
      w,
      generate_series(1, case when w = 1 then 4 else 3 end) as c
    from weeks
  ),
  levels as (
    select generate_series(2, 5) as m  -- niveaux 2 à 5 uniquement
  ),
  forge_ids as (
    select format('a%s_c%s_m%s', cards.w, cards.c, levels.m) as module_id
    from cards
    cross join levels
  ),
  upsert_forge_entries as (
    insert into public.user_module_state_entries (user_id, module_id, status, available_at, completed_at, content)
    select p.uid, f.module_id, 'available', now(), null, '{}'::jsonb
    from params p
    cross join forge_ids f
    on conflict (user_id, module_id) do update
      set
        status = case when public.user_module_state_entries.status = 'completed' then 'completed' else 'available' end,
        available_at = least(public.user_module_state_entries.available_at, excluded.available_at),
        completed_at = case when public.user_module_state_entries.status = 'completed' then public.user_module_state_entries.completed_at else null end,
        updated_at = now()
    returning 1
  )

select
  (select count(*) from upsert_week_states)   as week_states_touched,
  (select count(*) from upsert_forge_entries) as forge_modules_touched;

commit;




Lancer la fonction trigger memory echo : 

curl -s -X POST "http://127.0.0.1:54321/functions/v1/trigger-memory-echo" \
  -H "Content-Type: application/json" \
  -H "X-Internal-Secret: sophia-_on_earth" \
  -d '{"email":"thomasgenty30@gmail.com","force":true,"debug":true}'


  Pour lancer bilan spécifique : 
  cd "/Users/ahmedamara/Dev/Sophia 2/frontend"
node scripts/run_ui_bilan_eval_bundle.mjs \
  --turns 15 \
  --bilan-actions 3 \
  --difficulty mid \
  --model gemini-2.5-flash \
  --timeout-ms 600000 \
  --post-bilan

  Poour lanceer test onboarding whatsapp : 
  cd "/Users/ahmedamara/Dev/Sophia 2/frontend"
npm run eval:wa:onboarding:bundle -- --tests 10 --seed 123 --turns 8 --model gemini-2.5-flash --timeout-ms 600000


Pour lancer test pour les tools : 
npm run eval:tools -- --scenario tools_create_action


Chargé bon environnement : 

cd "/Users/ahmedamara/Dev/Sophia 2" && supabase functions serve --env-file supabase/.env


-- ═══════════════════════════════════════════════════════════════════════════════
-- RESET COMPLET POUR REFAIRE LE BILAN (J-2)
-- Exécute tout d'un coup, et remplace le UUID UNE SEULE FOIS dans p_user_id
-- ═══════════════════════════════════════════════════════════════════════════════

DO $$
DECLARE
  p_user_id uuid := '00000000-0000-0000-0000-000000000000'; -- <- remplace UNIQUEMENT ça
  p_past timestamptz := now() - interval '2 days';
BEGIN
  -- 1) Reset le log du bilan d'aujourd'hui à J-2 (au lieu de supprimer)
  -- Note: si tu as plusieurs logs "aujourd'hui", ils seront tous repoussés à J-2.
  UPDATE public.user_checkup_logs
  SET completed_at = p_past
  WHERE user_id = p_user_id
    AND completed_at::date = CURRENT_DATE;

  -- 2) Reset updated_at de user_chat_states (trigger le remet à NOW() sinon)
  ALTER TABLE public.user_chat_states DISABLE TRIGGER update_user_chat_states_modtime;
  UPDATE public.user_chat_states
  SET updated_at = p_past
  WHERE user_id = p_user_id;
  ALTER TABLE public.user_chat_states ENABLE TRIGGER update_user_chat_states_modtime;

  -- 3) Reset actions actives (clé réelle pour le bilan: last_performed_at)
  UPDATE public.user_actions
  SET last_performed_at = p_past,
      updated_at = p_past
  WHERE user_id = p_user_id
    AND status = 'active';

  -- 4) Reset vital signs actifs (clé réelle pour le bilan: last_checked_at)
  UPDATE public.user_vital_signs
  SET last_checked_at = p_past,
      updated_at = p_past
  WHERE user_id = p_user_id
    AND status = 'active';

  -- 5) (Optionnel) Reset frameworks aussi
  UPDATE public.user_framework_tracking
  SET last_performed_at = p_past,
      updated_at = p_past
  WHERE user_id = p_user_id
    AND status = 'active';
END;
$$;


J'aurais besoin que tu m'aides à review ce qui a été mis en place niveau code dans ce plan :

Il faut que tu identifies les bugs et les incohérences, et qu. tu procèdes au fixs s'il te plait 




Commande pour lancer onboarding web :
# 1-liner (clean + launch) — remplace EMAIL/PASSWORD si besoin
SUPABASE_URL="http://127.0.0.1:54321" SUPABASE_ANON_KEY="sb_publishable_ACJWlzQHlZjBrEguHvfOxg_3BJgxAaH" EMAIL="i@i.com" PASSWORD="1234567" USER_ID="2e4eba1c-a49c-43e1-a308-8dc6362e5d33" TOKEN="$(curl -s "$SUPABASE_URL/auth/v1/token?grant_type=password" -H "apikey: $SUPABASE_ANON_KEY" -H "Content-Type: application/json" -d "{\"email\":\"$EMAIL\",\"password\":\"$PASSWORD\"}" | python3 -c 'import sys,json; print(json.load(sys.stdin).get("access_token",""))')" && curl -s -X DELETE "$SUPABASE_URL/rest/v1/chat_messages?user_id=eq.$USER_ID&scope=eq.web_onboarding" -H "apikey: $SUPABASE_ANON_KEY" -H "Authorization: Bearer $TOKEN" -H "Prefer: return=minimal" && curl -s "$SUPABASE_URL/functions/v1/sophia-brain" -H "apikey: $SUPABASE_ANON_KEY" -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" -d '{"message":"Ok, on commence l'\''onboarding.","channel":"web","scope":"web_onboarding","force_onboarding_flow":true}'




Prompt 1 — Analyse des bundles (transcripts + brain trace) + priorisation :--------------------------------------------------------------------------

Tu es un expert senior en conversation IA, machines à états, systèmes hybrides (LLM + règles), et debugging prod.
Ta mission: analyser des bundles extraits de prod (un dossier par conversation) et produire un rapport actionnable pour améliorer Sophia.

## Entrées
Je te fournis une liste de dossiers "bundle", chacun contient exactement:
- `conversation_transcript.txt` (transcript horodaté, avec role et request_id)
- `brain_trace.jsonl` (1 ligne JSON par turn; contient `{ ts_db, payload }` où `payload.details.brain_trace_events` est la trace)

Bundles à analyser:
- Voir à la fin 

## Contraintes & hygiène
- Ne jamais ré-imprimer de PII (téléphone, email, noms complets, adresses). Si présent dans les transcripts, anonymise: `<PHONE>`, `<EMAIL>`, `<NAME>`.
- Si une cause n’est pas prouvable avec les fichiers fournis, formule-la comme hypothèse et ajoute “comment vérifier”.
- Important: toute détection de signaux doit être HYBRIDE: LLM (interprétation) + règles/regex (validation/garde-fous). Jamais “regex seule” comme logique principale.

## Objectif
1) Identifier les blocages/problèmes/loops/erreurs conversationnelles (UX, ton, timing, compréhension, safety, routing, toolflow, onboarding, etc.)
2) Pour chaque problème, recouper avec la brain trace pour expliquer “comment le cerveau y est arrivé”.
3) Prioriser les problèmes par sévérité ET fréquence (répétition chez les usagers / dans les bundles).
4) Proposer une solution rapide (overview) par item, orientée “patch minimal, testable”.

## Format de sortie (STRICT)
### A. Résumé exécutif (10 lignes max)
- 3-7 problèmes majeurs
- 3 métriques simples: nb bundles, nb turns analysés, top 3 catégories de panne

### B. Tableau de priorisation (trié du plus important au moins important)
Pour chaque ligne (un problème), retourne exactement ces colonnes:
- `id`
- `sévérité` (critical|high|medium|low)
- `fréquence` (nb bundles impactés / nb occurrences)
- `symptôme user` (1 phrase)
- `cause probable (1-2)` (pas plus)
- `preuves transcript` (2 extraits MAX avec timestamp + role + request_id)
- `preuves trace` (2 extraits MAX avec request_id + event + phase + 1 champ clé du payload)
- `solution proposée (overview)` (1-3 bullets)
- `risque de régression` (low|med|high + pourquoi en 1 phrase)

### C. Détail par problème (dans l’ordre du tableau)
Pour chaque `id`:
1) Contexte et impact
2) Analyse conversationnelle (humain)
3) Analyse “cerveau” (routing / dispatcher / context / agent / flow_resolution / interrupts / toolflow)
4) Hypothèses alternatives (si ambigu) + comment trancher
5) Fix proposé (design)
6) “Signal detection” hybride recommandé (LLM + regex/garde-fou + fallback)
7) Tests/validation recommandés (prod-safe)

## Rubrique de sévérité (à appliquer)
- critical: bug bloquant, boucle dure, safety, ou dégradation majeure de confiance
- high: confusion récurrente, réponses incorrectes importantes, routing souvent mauvais
- medium: incohérences, friction UX, ton, manque de clarté
- low: polish, micro-optimisations, wording

Commence par lire tous les bundles. Ensuite produis A, B, puis C.
NB: abracadabra (dans un seul message) est une commande communiquer pour réinitaliser toutes les machines à état des user tests pour éviter qu'ils se retrouvent dans une boucle.
Nom du fichier qui inclu bundles à analyser :


Prompt 2 — Implémenter les fixes (sans régression) + patch plan : -------------------------------------------------------------------

Tu es un ingénieur principal responsable d’améliorer le système conversationnel Sophia, sans régression.
Tu reçois une liste priorisée de problèmes (issue backlog) basée sur des bundles prod + traces.

## Entrées
- Repo code Sophia (Edge Functions + frontend + SQL migrations)
- Tout ce qui s'ets dit dans notre précédente conversation en terme de pacth solution problème, disucssion ect..

## Principes non négociables
- Corriger d’abord: critical → high → medium → low.
- Changements minimaux, ciblés, réversibles.
- Toute détection de signaux = HYBRIDE: LLM propose/interprète + regex/règles valident/contraignent (pas regex seule).
- Pas de “refactor global” sauf nécessité prouvée.
- Ne pas casser WhatsApp vs web, ni scopes modules.

## Workflow attendu (STRICT)
### 1) Reconnaissance ciblée
Pour chaque issue (dans l’ordre):
- Où dans le code ça vit (fichiers / fonctions / state machine)
- Quels comportements voisins risquent d’être impactés
- Quel est le “contrat” actuel (inputs/outputs, invariants)

### 2) Plan de patch
Pour chaque issue:
- Changement exact (1-3 bullets)
- Fichiers touchés
- Stratégie hybride (LLM + validation règles)
- Stratégie de compat/rétro-compat (si schéma/metadata)
- Risques & mitigations

### 3) Implémentation
- Applique les changements.
- Ajoute/ajuste les tests pertinents (unit/int) ou, si pas possible, des checks prod-safe (logging/guards).
- Si tu modifies le routing/dispatcher: ajoute au moins un garde-fou anti-loop.

### 4) Vérification non-régression
- Vérifie localement (ou via tests existants) que les flows critiques ne cassent pas.
- Ajoute une checklist “avant/après” par issue (comportement attendu).

## Format de sortie (STRICT)
- `Changelog` (par issue)
- `Diff summary` (liste de fichiers + intention)
- `Tests/Checks` (ce qui a été exécuté + ce que ça couvre)
- `Rollout plan` (si pertinent: feature flags, logs, monitoring)
- `Follow-ups` (dettes techniques / améliorations futures)

Commence par la 1ère issue critical et avance séquentiellement.
Si une issue demande une décision produit (copy/ton), propose 2 variantes et choisis la plus sûre. 