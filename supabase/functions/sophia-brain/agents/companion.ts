import { SupabaseClient } from 'jsr:@supabase/supabase-js@2'
import { generateWithGemini, generateEmbedding } from '../../_shared/gemini.ts'
import { handleTracking } from "../lib/tracking.ts"
import { logEdgeFunctionError } from "../../_shared/error-log.ts"

export type CompanionModelOutput =
  | string
  | { tool: "track_progress"; args: any }

export type CompanionRunResult = {
  text: string
  executed_tools: string[]
  tool_execution: "none" | "blocked" | "success" | "failed" | "uncertain"
}

export function buildCompanionSystemPrompt(opts: {
  isWhatsApp: boolean
  lastAssistantMessage: string
  context: string
  userState: any
}): string {
  const { isWhatsApp, lastAssistantMessage, context, userState } = opts
  const basePrompt = isWhatsApp ? `
    Tu es Sophia, une coach de vie orient√©e action.
    Tu tutoies l'utilisateur. Tu √©cris comme un humain, naturel, direct.

    MODE WHATSAPP (CRITIQUE) :
    - R√©ponse courte par d√©faut (2‚Äì6 lignes).
    - 1 question MAX.
    - Si le message user est court/press√©: 1‚Äì2 phrases MAX + 1 question oui/non ou A/B.
    - Pas de "Bonjour/Salut" au milieu d'une conversation.
    - Pas de ** (texte brut uniquement).
    - Emojis: 1 √† 2 emojis max par message (minimum 1), plac√©s naturellement; pas une ligne enti√®re d'emojis. Tu peux utiliser n'importe quel emoji Unicode.
    - N'invente JAMAIS de limitations techniques fictives (ex: "je n'ai pas acc√®s √† X", "ma biblioth√®que est limit√©e"). Si tu ne sais pas, dis-le simplement.
    - Ne mentionne jamais des r√¥les internes (architecte/investigator/etc.) ni "je suis une IA".
    - Si tu utilises le contexte, ne l'expose pas ("je vois dans ta base..."): juste utilise-le.

    TON JOB :
    - Avant de r√©pondre, reconstitue mentalement le fil depuis le FIL ROUGE + l'historique r√©cent.
    - R√©ponds toujours au DERNIER message utilisateur en priorit√©, sans perdre la coh√©rence du fil.
    - R√©ponds d'abord √† ce que l'utilisateur dit.
    - Ensuite, propose UNE relance utile (ou une micro-question) sans changer de sujet.

    ADD-ONS / MACHINES (CRITIQUE) :
    - Si le contexte contient "=== SESSION TOPIC ACTIVE ===", respecte la phase et reste sur le sujet.
    - Si le contexte contient "=== ADDON BILAN", applique strictement l'instruction (1 question max).
    - Si le contexte contient "=== ADDON TRACK_PROGRESS", suis la consigne (clarifier si besoin, sinon acquiescer).
    - Si le contexte contient "=== ADDON DASHBOARD REDIRECT ===", suis strictement la redirection dashboard.
    - Si le contexte contient "=== ADDON SAFETY ACTIVE ===", priorise l'apaisement: ton calme, validation, une seule micro-question.

    DASHBOARD-FIRST (CRITIQUE) :
    - Si l'utilisateur veut cr√©er/modifier/activer/supprimer/mettre en pause une action:
      - Tu l'aides avec une r√©ponse coaching courte
      - Puis tu rediriges explicitement vers le tableau de bord pour effectuer l'op√©ration
      - Tu n'annonces jamais qu'une action a √©t√© modifi√©e depuis le chat.

    TRACKING :
    - Si l'utilisateur dit qu'il a FAIT une action/habitude: appelle l'outil track_progress (status=completed).
    - S'il dit qu'il ne l'a PAS faite: track_progress (status=missed, value=0).

    ACTIONS COMPLETED (CRITIQUE) :
    - Si le contexte contient des actions marqu√©es "completed", NE LES MENTIONNE PAS de toi-m√™me.
    - Tu n'en parles QUE si l'utilisateur en parle en premier. Sinon, ignore-les.

    USER MODEL (PR√âF√âRENCES - 10 types) :
    - Le contexte peut contenir "=== USER MODEL (FACTS) ===".
    - Si des facts existent, adapte ton style/timing sans le dire.

    DERNI√àRE R√âPONSE DE SOPHIA : "${lastAssistantMessage.substring(0, 120)}..."

    CONTEXTE (si pr√©sent) :
    ${context ? context : "(vide)"}
  ` : `
    Tu es Sophia, une coach de vie orient√©e action.
    Tu n'es PAS une assistante, ni une IA g√©n√©rique. Tu es une "Partenaire de Vie".
    Ton but n'est pas de "servir", mais d'AVANCER avec l'utilisateur.

    DERNI√àRE R√âPONSE DE SOPHIA : "${lastAssistantMessage.substring(0, 100)}..."
    
    TON STYLE (ORGANIC & FLUIDE) :
    - √âcris comme on parle (Oralit√©). Utilise des tournures directes.
    - Sois r√©active : Si l'utilisateur dit un truc triste, ne dis pas "Je comprends", dis "Ah merde..." ou "C'est dur √ßa."
    - Humour subtil autoris√©.
    - INTERDICTION FORMELLE D'UTILISER LE GRAS (les ast√©risques **). √âcris en texte brut.
    - Emojis: 1 √† 2 emojis max par message (minimum 1), plac√©s naturellement; pas une ligne enti√®re d'emojis. Tu peux utiliser n'importe quel emoji Unicode.
    - N'invente JAMAIS de limitations techniques fictives. Si tu ne sais pas, dis-le simplement.
    - NE JAMAIS DIRE AU REVOIR OU BONNE SOIR√âE EN PREMIER. Sauf si l'utilisateur le dit explicitement.
    - NE JAMAIS DIRE BONJOUR OU SALUT AU MILIEU D'UNE CONVERSATION. Si l'utilisateur ne dit pas bonjour dans son dernier message, tu ne dis pas bonjour non plus.
    - Ton but est de maintenir la conversation ouverte et engageante.
    - Ne r√©v√®le jamais des noms de r√¥les internes (architecte/assistant/investigator/etc.). Ne dis jamais "en tant que ..." ou "je suis une IA".

    ADAPTATION AU TON (CRITIQUE) :
    - Observe le ton du user. S'il √©crit court / press√© ("oui", "ok", "suite", "vas-y"), toi aussi: 1‚Äì2 phrases max + 1 question.
    - √âvite les envol√©es + slogans. Pas de slang type "gnaque", "souffl√©", etc.
    - Quand le user confirme une micro-action ("oui c'est bon"): valide en 3‚Äì6 mots MAX, puis passe √† l'√©tape suivante.
    - N'encha√Æne PAS avec "comment tu te sens ?" sauf si le user exprime une √©motion (stress, peur, motivation, fatigue).
    - R√àGLE STRICTE (user press√©) : si le dernier message du user fait <= 30 caract√®res OU contient "ok", "oui", "vas-y", "suite", "go", "on y va":
      - MAX 2 phrases.
      - Puis 1 question courte (oui/non ou A/B).
      - Interdiction des paragraphes longs.

    COH√âRENCE CONTEXTUELLE (CRITIQUE) :
    - Avant de r√©pondre, reconstruis le fil avec le FIL ROUGE + les ~15 derniers messages.
    - R√©ponds d'abord au DERNIER message, puis garde la continuit√© conversationnelle.

    ADD-ONS / MACHINES (CRITIQUE) :
    - Si le contexte contient "=== SESSION TOPIC ACTIVE ===", respecte la phase et reste sur le sujet.
    - Si le contexte contient "=== ADDON BILAN", applique strictement l'instruction (1 question max).
    - Si le contexte contient "=== ADDON TRACK_PROGRESS", suis la consigne (clarifier si besoin, sinon acquiescer).
    - Si le contexte contient "=== ADDON DASHBOARD REDIRECT ===", suis strictement la redirection dashboard.
    - Si le contexte contient "=== ADDON SAFETY ACTIVE ===", priorise l'apaisement: validation √©motionnelle + 1 seule micro-question.

    DASHBOARD-FIRST (CRITIQUE) :
    - Si l'utilisateur veut cr√©er/modifier/activer/supprimer/mettre en pause une action:
      - Tu aides d'abord (coaching, reformulation, clarification rapide),
      - puis tu rediriges clairement vers le tableau de bord pour faire l'op√©ration.
    - Interdit d'affirmer qu'une action a √©t√© cr√©√©e/modifi√©e/activ√©e/supprim√©e depuis le chat.

    USER MODEL (PR√âF√âRENCES - 10 types) :
    - Le contexte peut contenir "=== USER MODEL (FACTS) ===".
    
    TYPES DE FAITS PERSONNELS (10):
    1. conversation.tone: ton de communication ("direct", "doux", "cash")
    2. conversation.verbosity: longueur des reponses ("concis", "detaille")
    3. conversation.use_emojis: preference emojis ("avec", "sans", "peu")
    4. schedule.work_hours: horaires de travail ("9h-18h", "mi-temps")
    5. schedule.energy_peaks: moments d'energie ("matin", "soir")
    6. schedule.wake_time: heure de reveil ("6h30", "7h")
    7. schedule.sleep_time: heure de coucher ("23h", "minuit")
    8. personal.job: metier ("developpeur", "medecin")
    9. personal.hobbies: loisirs ("course", "lecture")
    10. personal.family: situation familiale ("2 enfants", "celibataire")
    
    - Si des facts existent, adapte ton style/timing sans le dire.

    ACTIONS COMPLETED (CRITIQUE) :
    - Si le contexte contient des actions marqu√©es "completed", NE LES MENTIONNE PAS de toi-m√™me.
    - Tu n'en parles QUE si l'utilisateur en parle en premier. Sinon, ignore-les compl√®tement.

    ONBOARDING / CONTEXTE (CRITIQUE) :
    - N'affirme jamais "on a X dans ton plan" / "dans le plan" / "c'est pr√©vu dans ton plan"
      sauf si le CONTEXTE OP√âRATIONNEL indique explicitement une action active correspondante.

    CONTEXTE UTILISATEUR :
    - Risque actuel : ${userState?.risk_level ?? 0}/10
    ${context ? `\nCONTEXTE VIVANT (Ce que l'on sait de lui MAINTENANT) :\n${context}` : ""}
  `
  return basePrompt
}

/**
 * Options for retrieveContext
 */
export interface RetrieveContextOptions {
  /** Maximum number of memory results (default: 5) */
  maxResults?: number
  /** Whether to include action history (default: true) */
  includeActionHistory?: boolean
}

// RAG Helper EXPORT√â (Utilis√© par le router)
export async function retrieveContext(
  supabase: SupabaseClient, 
  userId: string, 
  message: string,
  opts?: RetrieveContextOptions
): Promise<string> {
  const maxResults = opts?.maxResults ?? 5
  const includeActionHistory = opts?.includeActionHistory ?? true
  // For minimal mode (firefighter), we limit action history too
  const actionResultsCount = maxResults <= 2 ? 1 : 3
  
  let contextString = "";
  try {
    const embedding = await generateEmbedding(message);

    // 1. Souvenirs (Memories)
    // IMPORTANT:
    // - On web, the client is authed as the user -> auth.uid() works (use match_memories).
    // - On WhatsApp, we call Sophia via a service_role client -> auth.uid() is NULL.
    //   We therefore use service-role-only RPCs that accept an explicit user_id.
    const { data: memories, error: memErr } = await supabase.rpc('match_memories_for_user', {
      target_user_id: userId,
      query_embedding: embedding,
      match_threshold: 0.65,
      match_count: maxResults,
      filter_status: ["consolidated"],
    } as any);
    const { data: memoriesFallback } = memErr
      ? await supabase.rpc('match_memories', {
        query_embedding: embedding,
        match_threshold: 0.65,
        match_count: maxResults,
        filter_status: ["consolidated"],
      } as any)
      : ({ data: null } as any);
    const effectiveMemories = (memErr ? memoriesFallback : memories) as any[] | null;

    if (effectiveMemories && effectiveMemories.length > 0) {
        contextString += effectiveMemories.map((m: any) => {
          const dateStr = m.created_at ? new Date(m.created_at).toLocaleDateString('fr-FR') : 'Date inconnue';
          return `[Souvenir (${m.source_type}) du ${dateStr}] : ${m.content}`;
        }).join('\n\n');
        contextString += "\n\n";
    }

    // 2. Historique des Actions (Action Entries)
    // On cherche si des actions pass√©es (r√©ussites ou √©checs) sont pertinentes pour la discussion
    // Skip for minimal mode (firefighter) if explicitly disabled
    if (includeActionHistory) {
      const { data: actionEntries, error: actErr } = await supabase.rpc('match_all_action_entries_for_user', {
        target_user_id: userId,
        query_embedding: embedding,
        match_threshold: 0.60,
        match_count: actionResultsCount,
      } as any);
      const { data: actionEntriesFallback } = actErr
        ? await supabase.rpc('match_all_action_entries', {
          query_embedding: embedding,
          match_threshold: 0.60,
          match_count: actionResultsCount,
        } as any)
        : ({ data: null } as any);
      const effectiveActionEntries = (actErr ? actionEntriesFallback : actionEntries) as any[] | null;

      if (effectiveActionEntries && effectiveActionEntries.length > 0) {
          contextString += "=== HISTORIQUE DES ACTIONS PERTINENTES ===\n"
          contextString += effectiveActionEntries.map((e: any) => {
               const dateStr = new Date(e.performed_at).toLocaleDateString('fr-FR');
               const statusIcon = e.status === 'completed' ? '‚úÖ' : '‚ùå';
               return `[${dateStr}] ${statusIcon} ${e.action_title} : "${e.note || 'Pas de note'}"`;
          }).join('\n');
          contextString += "\n\n";
      }
    }

    return contextString;
  } catch (err) {
    console.error("Error retrieving context:", err);
    return "";
  }
}

// --- OUTILS ---
const TRACK_PROGRESS_TOOL = {
  name: "track_progress",
  description: "Enregistre une progression ou un rat√© (Action faite, Pas faite, ou Signe Vital mesur√©). √Ä utiliser quand l'utilisateur dit 'J'ai fait mon sport' ou 'J'ai rat√© mon sport'.",
  parameters: {
    type: "OBJECT",
    properties: {
      target_name: { type: "STRING", description: "Nom approximatif de l'action ou du signe vital." },
      value: { type: "NUMBER", description: "Valeur √† ajouter (ex: 1 pour 'J'ai fait', 0 pour 'Rat√©')." },
      operation: { type: "STRING", enum: ["add", "set"], description: "'add' = ajouter au total existant, 'set' = d√©finir la valeur absolue." },
      status: { type: "STRING", enum: ["completed", "missed", "partial"], description: "Statut de l'action : 'completed' (fait), 'missed' (pas fait/rat√©), 'partial' (√† moiti√©)." },
      date: { type: "STRING", description: "Date concern√©e (YYYY-MM-DD). Laisser vide pour aujourd'hui." }
    },
    required: ["target_name", "value", "operation"]
  }
}

export async function generateCompanionModelOutput(opts: {
  systemPrompt: string
  message: string
  history: any[]
  meta?: { requestId?: string; forceRealAi?: boolean; channel?: "web" | "whatsapp"; model?: string; temperature?: number }
}): Promise<CompanionModelOutput> {
  const isEvalLike =
    String(opts.meta?.requestId ?? "").includes(":tools:") ||
    String(opts.meta?.requestId ?? "").includes(":eval");
  // IMPORTANT: do not hardcode Gemini preview models in prod.
  // Let `generateWithGemini` pick its default model chain (defaults to gpt-5-mini) unless meta.model overrides.
  const DEFAULT_MODEL = isEvalLike ? "gemini-2.5-flash" : undefined;
  const historyText = (opts.history ?? []).slice(-5).map((m: any) => `${m.role}: ${m.content}`).join('\n')
  const temperature = Number.isFinite(Number(opts.meta?.temperature)) ? Number(opts.meta?.temperature) : 0.7
  const response = await generateWithGemini(
    opts.systemPrompt,
    `Historique:\n${historyText}\n\nUser: ${opts.message}`,
    temperature,
    false,
    [TRACK_PROGRESS_TOOL],
    "auto",
    {
      requestId: opts.meta?.requestId,
      model: opts.meta?.model ?? DEFAULT_MODEL,
      source: "sophia-brain:companion",
      forceRealAi: opts.meta?.forceRealAi,
    },
  )
  return response as any
}

export async function handleCompanionModelOutput(opts: {
  supabase: SupabaseClient
  userId: string
  scope: string
  message: string
  response: CompanionModelOutput
  meta?: { requestId?: string; forceRealAi?: boolean; channel?: "web" | "whatsapp"; model?: string }
}): Promise<CompanionRunResult> {
  const { supabase, userId, scope, message, response, meta } = opts

  if (typeof response === 'string') {
    return { text: response.replace(/\*\*/g, ''), executed_tools: [], tool_execution: "none" }
  }

  if (typeof response === 'object' && (response as any)?.tool === 'track_progress') {
    const toolName = "track_progress"
    try {
      console.log(`[Companion] üõ†Ô∏è Tool Call: track_progress`)
      await handleTracking(supabase, userId, (response as any).args, { source: meta?.channel ?? "chat" })

      const confirmationPrompt = `
        ACTION VALID√âE : "${(response as any).args?.target_name ?? ""}"
        STATUT : ${(response as any).args?.status === 'missed' ? 'Rat√© / Pas fait' : 'R√©ussi / Fait'}
        
        CONTEXTE CONVERSATION (POUR √âVITER LES R√âP√âTITIONS) :
        Dernier message de l'utilisateur : "${message}"
        
        TA MISSION :
        1. Confirme que c'est pris en compte (sans dire "C'est enregistr√© dans la base de donn√©es").
        2. F√©licite (si r√©ussi) ou Encourage (si rat√©).
        3. SI l'utilisateur a donn√© des d√©tails, REBONDIS SUR CES D√âTAILS. Ne pose pas une question g√©n√©rique.

        FORMAT :
        - R√©ponse a√©r√©e en 2 petits paragraphes s√©par√©s par une ligne vide.
        - Pas de gras.
      `
      const confirmationResponse = await generateWithGemini(confirmationPrompt, "Confirme et encha√Æne.", 0.7, false, [], "auto", {
        requestId: meta?.requestId,
        model: meta?.model ?? (String(meta?.requestId ?? "").includes(":tools:") ? "gemini-2.5-flash" : undefined),
        source: "sophia-brain:companion_confirmation",
        forceRealAi: meta?.forceRealAi,
      })
      return {
        text: typeof confirmationResponse === 'string'
          ? confirmationResponse.replace(/\*\*/g, '')
          : "√áa marche, c'est not√©.",
        executed_tools: [toolName],
        tool_execution: "success",
      }
    } catch (e) {
      const errMsg = e instanceof Error ? e.message : String(e)
      console.error("[Companion] tool execution failed (unexpected):", errMsg)
      // System error log (admin production log)
      await logEdgeFunctionError({
        functionName: "sophia-brain",
        error: e,
        severity: "error",
        title: "tool_execution_failed_unexpected",
        requestId: meta?.requestId ?? null,
        userId,
        source: "sophia-brain:companion",
        metadata: { reason: "tool_execution_failed_unexpected", tool_name: toolName, channel: meta?.channel ?? "web" },
      })
      // Best-effort eval trace (during eval runs only).
      try {
        const { logVerifierEvalEvent } = await import("../lib/verifier_eval_log.ts")
        const rid = String(meta?.requestId ?? "").trim()
        if (rid) {
          await logVerifierEvalEvent({
            supabase: supabase as any,
            requestId: rid,
            source: "sophia-brain:verifier",
            event: "verifier_tool_execution_fallback",
            level: "warn",
            payload: {
              verifier_kind: "verifier_1:tool_execution_fallback",
              agent_used: "companion",
              channel: meta?.channel ?? "web",
              tool_name: toolName,
              err: errMsg.slice(0, 240),
            },
          })
        }
      } catch {}
      return {
        text: `Ok, j‚Äôai eu un souci technique en notant √ßa.\n\nDis ‚Äúretente‚Äù et je r√©essaie.`,
        executed_tools: [toolName],
        tool_execution: "failed",
      }
    }
  }

  // Catch-all: never stringify arbitrary objects into chat (it becomes "[object Object]").
  // If we get an unexpected tool call, return a safe user-facing message and log.
  if (response && typeof response === "object") {
    const maybeTool = (response as any)?.tool ?? null
    const maybeText =
      (response as any)?.text ??
      (response as any)?.message ??
      (response as any)?.next_message ??
      null
    if (typeof maybeText === "string" && maybeText.trim()) {
      return { text: maybeText.replace(/\*\*/g, ""), executed_tools: [], tool_execution: "none" }
    }
    if (maybeTool) {
      console.warn("[Companion] Unexpected tool call (ignored):", maybeTool)
      return { text: "Ok ‚Äî je te suis. On continue.", executed_tools: [], tool_execution: "blocked" }
    }
    console.warn("[Companion] Unexpected non-string response (ignored).")
    return { text: "Ok ‚Äî je te suis. On continue.", executed_tools: [], tool_execution: "none" }
  }

  return { text: String(response ?? ""), executed_tools: [], tool_execution: "none" }
}

export async function runCompanion(
  supabase: SupabaseClient,
  userId: string,
  scope: string,
  message: string, 
  history: any[], 
  userState: any, 
  context: string = "",
  meta?: { requestId?: string; forceRealAi?: boolean; channel?: "web" | "whatsapp"; model?: string }
): Promise<CompanionRunResult> {
  const lastAssistantMessage = history.filter((m: any) => m.role === 'assistant').pop()?.content || "";
  const isWhatsApp = (meta?.channel ?? "web") === "whatsapp"

  const systemPrompt = buildCompanionSystemPrompt({ isWhatsApp, lastAssistantMessage, context, userState })
  const response = await generateCompanionModelOutput({ systemPrompt, message, history, meta })
  return await handleCompanionModelOutput({ supabase, userId, scope, message, response, meta })
}
