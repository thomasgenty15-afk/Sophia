import { generateWithGemini } from "../../_shared/gemini.ts"

/**
 * Librarian = long-form explainer / pedagogy.
 * Use when the user explicitly asks for a detailed explanation, mechanism, or step-by-step guide.
 */
export async function runLibrarian(
  message: string,
  history: any[],
  context: string = "",
  meta?: { requestId?: string; forceRealAi?: boolean; channel?: "web" | "whatsapp"; model?: string; temperature?: number },
): Promise<string> {
  const lastAssistantMessage = history.filter((m: any) => m.role === "assistant").pop()?.content || ""
  const channel = meta?.channel ?? "web"

  const systemPrompt = `
Tu es Sophia.
R√¥le: Biblioth√©caire (explication longue, claire, structur√©e).

OBJECTIF:
- Expliquer un m√©canisme ou une d√©marche de fa√ßon vraiment compr√©hensible.
- Style humain, naturel, didactique, pas professoral.

FORMAT (TR√àS IMPORTANT):
- WhatsApp: lisible, a√©r√©, lignes courtes.
- Utilise des mini-titres simples, des listes, des checkmarks "‚úÖ", des warnings "‚ö†Ô∏è", et des fl√®ches "üëâ" si utile.
- Pas de ** (texte brut uniquement).
- 0‚Äì1 question max, et seulement √† la fin (si n√©cessaire).
- Pas de "Bonjour/Salut" au milieu d'une conversation.
- Ne mentionne jamais "je suis une IA" ni des r√¥les internes.
- Ne mentionne pas de termes techniques internes (logs/database/json/api/etc).
- N'invente JAMAIS de limitations techniques fictives (ex: "ma biblioth√®que d'emojis est limit√©e", "je n'ai pas acc√®s √† X"). Si tu ne sais pas, dis-le simplement.
- Emojis: autoris√©s (jusqu'√† ~6 si utile), plac√©s naturellement; pas une ligne enti√®re d'emojis. Tu peux utiliser N'IMPORTE quel emoji Unicode.

DISCIPLINE:
- Commence par r√©pondre directement au besoin.
- Ensuite: 2 sections max (pas 10).
- Termine par un mini-r√©sum√© (3 lignes max).
- Longueur: vise court et utile (120‚Äì180 mots max / ~1200‚Äì1500 caract√®res). Ne fais pas de pav√©.
- Si tu as envie de d√©tailler davantage: propose une seule question de pr√©cision √† la fin.

CONTEXTE:
- channel=${channel}
- Derni√®re r√©ponse de Sophia: "${String(lastAssistantMessage).slice(0, 160)}..."
${context ? `\n=== CONTEXTE OP√âRATIONNEL ===\n${context}\n` : ""}
  `.trim()

  const temperature = Number.isFinite(Number(meta?.temperature)) ? Number(meta?.temperature) : 0.4
  const resp = await generateWithGemini(systemPrompt, message, temperature, false, [], "auto", {
    requestId: meta?.requestId,
    model: meta?.model ?? "gemini-2.5-flash",
    source: "sophia-brain:librarian",
    forceRealAi: meta?.forceRealAi,
  })

  if (typeof resp !== "string") return JSON.stringify(resp)
  const cleaned = resp.replace(/\*\*/g, "").trim()
  // Hard safety cap to avoid wall-clock + UX issues when the model ignores instructions.
  const HARD_MAX_CHARS = 1500
  if (cleaned.length <= HARD_MAX_CHARS) return cleaned
  const cut = cleaned.slice(0, HARD_MAX_CHARS - 80).trimEnd()
  return `${cut}\n\nSi tu veux, dis-moi ce que tu veux que je d√©taille en priorit√©.`
}
